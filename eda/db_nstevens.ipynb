{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8040cf-1e95-4e78-b7d9-fabe28d723bb",
   "metadata": {},
   "source": [
    "## Notebook For Data Exploration from SQL Databases and Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afacf33e-f941-4ca1-b0dc-7cd4bf4d49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages and connect to the database\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine, text\n",
    "import pickle\n",
    "\n",
    "# set plotting theme to seaborn\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005fea1-9337-42b5-a2b6-b1cc7beb306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try connecting to the database\n",
    "engine = create_engine('postgresql+psycopg2://ns96:java100@localhost/SolarCostData')\n",
    "\n",
    "# make sure we can connect to the database, otherwise exit\n",
    "try:\n",
    "  conn = engine.connect()\n",
    "  conn.close()\n",
    "  print(\"Successfully Connected to DB\")\n",
    "except Exception as e:\n",
    "  print(\"DB Connection Error\\n\")    \n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0247a550-ba71-4d56-a8e4-baa16f506787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run query to return all cities, with installers, and average cost\n",
    "query = text('SELECT \"Service_City\", \"Installer_Name\", COUNT(\"Installer_Name\"), '\\\n",
    "             'ROUND(AVG(\"Total_System_Cost\")) '\\\n",
    "             'FROM \"CA\" '\\\n",
    "             'GROUP BY \"Service_City\", \"Installer_Name\" '\\\n",
    "             'HAVING \"Installer_Name\" != \\'Other\\' '\\\n",
    "             'ORDER BY \"Service_City\", COUNT(\"Installer_Name\") DESC')\n",
    "print(query)\n",
    "    \n",
    "with engine.connect() as conn:\n",
    "    results = conn.execute(query).fetchall()\n",
    "    \n",
    "    records = dict()\n",
    "    \n",
    "    for row in results:\n",
    "        print(row[0], row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c492dd8-3563-4cb7-a59c-c7958a1439b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a look table which indicate the most common generator used by an installer\n",
    "def make_generator_table():\n",
    "    global generator_table\n",
    "    \n",
    "    generator_table = dict()\n",
    "    query = text('SELECT \"Installer_Name\", \"Generator_Manufacturer\", '\\\n",
    "                  'COUNT(\"Generator_Manufacturer\"), ROUND(AVG(\"Generator_Quantity\")) '\\\n",
    "                  'FROM \"CA\" '\\\n",
    "                  'GROUP BY \"Installer_Name\", \"Generator_Manufacturer\" '\\\n",
    "                  'HAVING \"Installer_Name\" != \\'Other\\' '\\\n",
    "                  'ORDER BY \"Installer_Name\", COUNT(\"Generator_Manufacturer\") DESC')\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        results = conn.execute(query).fetchall()    \n",
    "        for row in results:\n",
    "            installer = row[0]\n",
    "        \n",
    "            if installer not in generator_table:\n",
    "                generator_table[installer] = (row[1], int(row[2]), int(row[3])) \n",
    "                #print(row)\n",
    "\n",
    "# create the generator lookup table\n",
    "make_generator_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fded63-0473-4a43-bad0-96dda653f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a city zip code return the top 10 installers and their average generator install cost. return utility\n",
    "# and array of tuples\n",
    "def get_installers(zip_code = '92130'):\n",
    "    utility_query = text('SELECT \"Utility\" FROM \"CA\" WHERE \"Service_Zip\" = \\'' + zip_code + '\\' LIMIT 1')\n",
    "    city_query = 'SELECT \"Service_City\" FROM \"CA\" WHERE \"Service_Zip\" = \\'' + zip_code + '\\' LIMIT 1'\n",
    "\n",
    "    query = text('SELECT \"Service_City\", \"Installer_Name\", COUNT(\"Installer_Name\"), '\\\n",
    "                 'ROUND (AVG(\"System_Size_AC\")), '\\\n",
    "                 'ROUND(AVG(\"Total_System_Cost\")) '\\\n",
    "                 'FROM \"CA\" '\\\n",
    "                 'WHERE \"Service_City\" = (' + city_query + ') '\\\n",
    "                 'GROUP BY \"Service_City\", \"Installer_Name\" '\\\n",
    "                 'HAVING \"Installer_Name\" != \\'Other\\' '\\\n",
    "                 'ORDER BY COUNT(\"Installer_Name\") DESC LIMIT 10')\n",
    "    \n",
    "    #print(query)\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        # get the untility\n",
    "        utility = conn.execute(utility_query).fetchall()[0][0]\n",
    "        print('Utility: ', utility)\n",
    "    \n",
    "        results = conn.execute(query).fetchall()    \n",
    "        records = list()\n",
    "        for row in results:\n",
    "            records.append(row)\n",
    "    \n",
    "    # return the utility and installer records \n",
    "    return utility, records\n",
    "\n",
    "# test the function\n",
    "get_installers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26bb06-0947-40d6-b201-6734617211d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the scaler and optimzed model\n",
    "scalers = dict()\n",
    "models = dict()\n",
    "\n",
    "# function to load the meachine learning models\n",
    "def load_models():\n",
    "    utilities  = ['SDGE', 'PGE', 'SCE']\n",
    "    for utility in utilities:\n",
    "        scaler_file = \"../models/scaler-\" + utility + \".pkl\"\n",
    "        model_file = \"../models/xgb_model-\" + utility + \".pkl\"\n",
    "\n",
    "        scalers[utility] = pickle.load(open(scaler_file, \"rb\"))\n",
    "        models[utility] = pickle.load(open(model_file, \"rb\"))\n",
    "\n",
    "# load the trained xgb boost models for testing\n",
    "load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d6e1a-72cf-4a7b-b94e-ca39a8d07be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to one hot encode and add all the needed columns for the scaler to work\n",
    "def one_hot_encode(df, train_features):\n",
    "    cat_columns = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "    enc = OneHotEncoder(sparse_output=False)\n",
    "    enc_data = enc.fit_transform(df[cat_columns])\n",
    "    enc_columns = enc.get_feature_names_out().tolist()\n",
    "\n",
    "    encode_df = pd.DataFrame(enc_data, columns=enc_columns)\n",
    "\n",
    "    # now lets merge the into the main dataframe then drop original columns\n",
    "    df = df.merge(encode_df, left_index=True, right_index=True)\n",
    "    df = df.drop(columns=cat_columns)\n",
    "\n",
    "    # add all the features that the model was trained on otherwise scaler/model won't work\n",
    "    for feature in train_features:\n",
    "        if feature not in df.columns:\n",
    "            series = pd.Series(0, index=df.index, name=feature)\n",
    "            df = pd.concat([df, series], axis=1)\n",
    "    \n",
    "    # re-order the feature names to be the same as what the scaler saw during training\n",
    "    df = df[train_features]\n",
    "    \n",
    "    # return the one hot encoded dataframe\n",
    "    return df\n",
    "    \n",
    "#function to make a prediction provided a dictionary containing variable to predict on\n",
    "def predict(utility, data):\n",
    "    # load the scaler and model\n",
    "    scaler = scalers[utility]\n",
    "    model = models[utility]\n",
    "\n",
    "    # convert the dictionary into a dataframe \n",
    "    df = pd.DataFrame(data)\n",
    "    #display(df)\n",
    "    \n",
    "    # one hot encode the data and scale it\n",
    "    train_features = scaler.feature_names_in_\n",
    "    df = one_hot_encode(df, train_features)\n",
    "    X_scaled = scaler.transform(df)\n",
    "\n",
    "    # make a prediction now\n",
    "    return model.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12776be6-7528-4194-b819-10baf32893f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test making a prediction\n",
    "utility = 'SDGE'\n",
    "\n",
    "test_data = {\n",
    "    'Service_City': ['SAN DIEGO', 'SAN DIEGO'], \n",
    "    'Technology_Type': ['Solar', 'Solar'],\n",
    "    'System_Size_AC': [7.0, 7.0],\n",
    "    'Storage_Size_kW_AC': [0, 0],\n",
    "    'Mounting_Method': ['Rooftop', 'Rooftop'],\n",
    "    'Installer_Name': ['Tesla', 'Tesla'],\n",
    "    'Third_Party_Owned': ['No', 'No'],\n",
    "    'Electric_Vehicle': ['No', 'Yes'],\n",
    "    'Generator_Manufacturer':['Other', 'Other'],\n",
    "    'Generator_Quantity': [12, 12]\n",
    "}\n",
    "\n",
    "predict(utility, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d2cbce-f587-402a-b342-49d92a3aac17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650ad93-423f-466b-9f9f-610b47f0441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions using zip codes\n",
    "def make_predictions(zipcode, kw, ecar):\n",
    "    pred_data = {\n",
    "        'Service_City': [],\n",
    "        'Technology_Type': [],\n",
    "        'System_Size_AC': [],\n",
    "        'Storage_Size_kW_AC': [],\n",
    "        'Mounting_Method': [],\n",
    "        'Installer_Name': [],\n",
    "        'Third_Party_Owned': [],\n",
    "        'Electric_Vehicle': [],\n",
    "        'Generator_Manufacturer': [],\n",
    "        'Generator_Quantity': []\n",
    "    }\n",
    "\n",
    "    # store this information\n",
    "    estimate_data = {\n",
    "        'Service_City': [],\n",
    "        'Installer_Name': [],\n",
    "        'Installation_Count': [],\n",
    "        'Avg_Size_AC': [],\n",
    "        'Avg_Cost': [],\n",
    "        'My_Size_AC': [],\n",
    "        'ECar': [],\n",
    "        'Est_Cost': []\n",
    "    }\n",
    "    \n",
    "    # get the utility and top 10 installers for the particular zipcode\n",
    "    utility, installers = get_installers(zipcode)\n",
    "    \n",
    "    for installer in installers:\n",
    "        #print(\"Installer Info:\", installer)\n",
    "        generator_info = generator_table[installer[1]]\n",
    "\n",
    "        # populate dictionary that gets returned with cost estimates\n",
    "        estimate_data['Service_City'].append(installer[0])\n",
    "        estimate_data['Installer_Name'].append(installer[1])\n",
    "        estimate_data['Installation_Count'].append(installer[2])\n",
    "        estimate_data['Avg_Size_AC'].append(installer[3])\n",
    "        estimate_data['Avg_Cost'].append(int(installer[4]))\n",
    "        estimate_data['My_Size_AC'].append(kw)\n",
    "        estimate_data['ECar'].append(ecar)\n",
    "        \n",
    "        # populate the dictionary with information for making predictions\n",
    "        pred_data['Service_City'].append(installer[0])\n",
    "        pred_data['Technology_Type'].append('Solar')\n",
    "        pred_data['System_Size_AC'].append(kw)\n",
    "        pred_data['Storage_Size_kW_AC'].append(0)\n",
    "        pred_data['Mounting_Method'].append('Rooftop')\n",
    "        pred_data['Installer_Name'].append(installer[1])\n",
    "        pred_data['Third_Party_Owned'].append('No')\n",
    "        pred_data['Electric_Vehicle'].append(ecar)\n",
    "        pred_data['Generator_Manufacturer'].append(generator_info[0]) # the most common generator used by installer\n",
    "        pred_data['Generator_Quantity'].append(int(generator_info[2])) # the average number of the above generator used\n",
    "\n",
    "    # now return the estimates and append to the dictionary so it can be turned info a dataframe\n",
    "    #print(\"Data to predict\", pred_data)\n",
    "    estimates = predict(utility, pred_data)\n",
    "    estimate_data['Est_Cost'] = [int(x) for x in estimates]\n",
    "\n",
    "    return estimate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0031c-de30-4e30-a1d6-7bb6dc64ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test making estimates SAN Diago\n",
    "estimates = make_predictions('92130', 5.0, 'No')\n",
    "df = pd.DataFrame(estimates)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2071a2-bcdd-4d9d-be9a-57bccdc0b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test making estimates SAN CLEMENTE\n",
    "estimates = make_predictions('92673', 2.8, 'No')\n",
    "df = pd.DataFrame(estimates)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d17af4-89f4-4969-8998-b8dc0963dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test making estimate in REDWOOD CITY\n",
    "estimates = make_predictions('94061', 8.0, 'No')\n",
    "df = pd.DataFrame(estimates)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ad659-d955-4290-8e79-ffb240891de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
