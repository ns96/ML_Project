{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcac0c8b-fddf-4309-8e3c-49abb9f65c0f",
   "metadata": {},
   "source": [
    "# ETL Notebook For Preparing Data For Tableau Exploration and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5687582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging files together\n",
    "\n",
    "# Specify the data files location\n",
    "data_dir = \"/Users/ns96/Documents/ML_Project/\"\n",
    "\n",
    "df_list = []\n",
    "for file in glob.glob(data_dir + \"*_year.csv\"):\n",
    "    print(file)\n",
    "    df_list.append(pd.read_csv(file, skipfooter=1))\n",
    "df = pd.concat(df_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c46763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with all NaN values\n",
    "df_cleaned = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d975e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some ids are repeated; although that's not a big number: 730 ids have repetitions across all files\n",
    "a = df['Application Id'].value_counts()\n",
    "a[a>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4505e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete repetitions\n",
    "df = df[~df['Application Id'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for repetitions again\n",
    "a = df['Application Id'].value_counts()\n",
    "a[a>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ecd290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though we downloaded data for the last five years from the website, the files still have old values.\n",
    "# Saving only last 5 years (2018-2023)\n",
    "\n",
    "# Convert 'App Received Date' column to datetime format\n",
    "df['App Received Date'] = pd.to_datetime(df['App Received Date'], errors='coerce')\n",
    "\n",
    "# Filter the DataFrame to keep only rows with 'App Received Date' on or after January 1, 2018\n",
    "df = df[df['App Received Date'] >= '2018-01-01']\n",
    "\n",
    "# Check the earliest date after filtering\n",
    "earliest_date_after_filtering = df['App Received Date'].min()\n",
    "\n",
    "# Display the result\n",
    "print(\"Earliest Date after Filtering:\", earliest_date_after_filtering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4457bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technology Type columns exploration\n",
    "# Top technology types\n",
    "top_technologies = df['Technology Type'].value_counts().head(25)\n",
    "top_technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing redundant datapoints\n",
    "valid_technology_types = ['Solar PV', 'Solar', 'Solar PV, Storage', 'Solar PV;Storage', 'Advanced Energy Storage', 'Storage', 'Energy Storage']\n",
    "\n",
    "# Filter the DataFrame to keep only the rows with valid technology types\n",
    "df = df[df['Technology Type'].isin(valid_technology_types)]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df['Technology Type'].value_counts().head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07932f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaming technology type datapoints\n",
    "df['Technology Type'] = df['Technology Type'].replace({'Solar PV': 'Solar', 'Solar PV;Storage': 'Solar, Storage',\\\n",
    "                                                       'Advanced Energy Storage': 'Storage', \\\n",
    "                                                      'Energy Storage': 'Storage'})\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df['Technology Type'].value_counts().head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Sector columns exploration\n",
    "customer_sectors = df['Customer Sector'].value_counts().head(25)\n",
    "customer_sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcaa4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing redundant datapoints\n",
    "valid_customer_sectors = ['Residential']\n",
    "\n",
    "# Filter the DataFrame to keep only the rows with valid customer sectors\n",
    "df = df[df['Customer Sector'].isin(valid_customer_sectors)]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df['Customer Sector'].value_counts().head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all column names\n",
    "column_names = df.columns.tolist()\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3aea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete redundant columns \n",
    "columns_to_remove = ['Application Id', 'Storage Capacity (kWh)', 'Tilt', \"Azimuth\",\n",
    "'Matched CSI Application Number', 'Electric Vehicle Count', 'System Output Monitoring', \\\n",
    "                     'System Output Reports To Vendor?', 'System Output Monitoring Provider', \\\n",
    "                     'NEM Tariff', 'Tracking', 'Interconnection Program', 'Application Status', 'System Size DC', \\\n",
    "                     'Project is VNEM, NEM-V, NEM-Agg?', 'Customer Sector', 'App Complete Date',\\\n",
    "                    'App Approved Date', 'Installer Phone', 'Installer City', 'Installer State', 'Installer Zip',\\\n",
    "                    'Pace Financed', 'Pace Financier', 'Previous Application', 'Previous Application Ids',\\\n",
    "                     'VNEM, NEM-V, NEM-Agg', 'NEMPV or nonNEMPV', 'VNEM ID', 'Match Somah Application']\n",
    "\n",
    "# Remove specified columns\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "\n",
    "# Display the DataFrame after removing columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49df78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty cells in \"Installer Name_standard_name\" column with \"Self-installed\" where \"Self Installer\" is \"yes\"\n",
    "df.loc[df['Self Installer'] == 'yes', 'Installer Name'] = df.loc[df['Self Installer'] == 'yes', 'Installer Name'].fillna('Self-installed')\n",
    "\n",
    "# Display the updated dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the column\n",
    "df_installer_names = df[['Installer Name']].copy()\n",
    "\n",
    "# Replace NaN values with 'Other'\n",
    "df_installer_names['Installer Name'].fillna('Other', inplace=True)\n",
    "\n",
    "df_installer_names = df_installer_names.rename(columns={'Installer Name': 'installer_name'})\n",
    "df_installer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_installer_names_counts = df_installer_names.groupby('installer_name').size().reset_index()\n",
    "df_installer_names_counts = df_installer_names_counts.rename(columns={0: 'counts'})\n",
    "df_installer_names_counts['pct'] = df_installer_names_counts['counts']/df_installer_names_counts['counts'].sum()\n",
    "df_installer_names_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff49d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base list of installers\n",
    "installers = {'Tesla': 1,\n",
    "             'SolarCity': 1,\n",
    "             'Sunrun': 1, \n",
    "             'Vivint': 1,\n",
    "             'SunPower': 1,\n",
    "             'PetersenDean': 2,\n",
    "             'Sungevity': 2,\n",
    "             'Spectrum': 2,\n",
    "             'Sunnova': 2,\n",
    "             'Baker': 2,\n",
    "             'Spruce': 2,\n",
    "             'Kilowatt': 2,\n",
    "             'CPF': 2,\n",
    "             'Sullivan': 2,\n",
    "             'Verengo': 2,\n",
    "             'ASI': 2,\n",
    "             'Semper': 2,\n",
    "             'Horizon': 2,\n",
    "             'Lennar': 2,\n",
    "             'SolarMax': 2,\n",
    "             'SunWorks': 2,\n",
    "             'The Solar Company': 2,\n",
    "             'Alternative Energy': 2,\n",
    "             'Stellar': 2,\n",
    "             'Westhaven': 2,\n",
    "             'Suncrest': 2,\n",
    "             'A1 Solar': 2,\n",
    "             'West Coast Solar': 2,\n",
    "             'Future Energy': 2,\n",
    "             'Smart Energy': 2,\n",
    "             'Enver Solar': 2,\n",
    "             'Bland': 3,\n",
    "             'Solar Universe': 3,\n",
    "             'Solcius': 3,\n",
    "             'Grid Alternatives': 3,\n",
    "             'Revolve Solar': 3,\n",
    "             'Solare Energy': 3,\n",
    "             'Helio': 3,\n",
    "             'NRG': 3,\n",
    "             'Clean Solar': 3,\n",
    "             'Sierra Pacific': 3,\n",
    "             '1st Light': 3,\n",
    "             'Cobalt': 3,\n",
    "             'Shorebreak': 3,\n",
    "             'Renova': 3,\n",
    "             'Arise': 3,\n",
    "             'Infinity Energy': 3,\n",
    "             'Planer': 3,\n",
    "             'Solartec': 3,\n",
    "             'LA Solar': 3,\n",
    "             'Fidelity': 3,\n",
    "             'Cosmic': 3,\n",
    "             'Fralick Homes': 3,\n",
    "             'Bay Area': 3,\n",
    "             'Natural Energy': 3,\n",
    "             'GCI': 3,\n",
    "             'Complete': 3,\n",
    "             'Secure Roofing': 3,\n",
    "             'Palomar Solar': 3,\n",
    "             'Solaire Energy': 3,\n",
    "             'Sun Solar Energy': 3,\n",
    "             'Sunline Energy': 3,\n",
    "             'Kuykendall': 3,\n",
    "             'Elevate': 3,\n",
    "             'Nexus Energy': 3,\n",
    "             'Sky Power': 3,\n",
    "             'Sunstreet': 3,\n",
    "             'Sunrise': 3,\n",
    "              'Alterra': 3,\n",
    "              'Millholland': 3,\n",
    "              'New Day Solar': 3,\n",
    "              'Hot Purple Energy': 3,\n",
    "              'Divine Power': 3,\n",
    "              'Precis': 3,\n",
    "              'SunFusion Solar': 3,\n",
    "              'SolarCraft Services': 3,\n",
    "              'Solarponics': 3,\n",
    "              'North State Solar': 3,\n",
    "              'Other': 3,\n",
    "              'Self-installed': 3}\n",
    "\n",
    "df_installer_names = df_installer_names.drop_duplicates()\n",
    "df_installer_names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY_SUFFIXES = ['com', 'in', 'int', 'international', 'inc', 'incorporated',\n",
    "                    'incorporation', 'corp', 'corporation', 'cos', 'co', '& co',\n",
    "                    'intl', 'ltd', 'limited', 'plc', 'llc', 'holdings', 'hldgs',\n",
    "                    'partners', 'cl', 'pl', 'technology', 'technologies', 'energy']\n",
    "import re\n",
    "def preprocess(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # removing punctuations in string\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # remove company suffixes:\n",
    "    text = ' '.join([p for p in text.split() if p not in COMPANY_SUFFIXES])\n",
    "    return text.strip()\n",
    "\n",
    "# preprocess candidate column\n",
    "installers_preprocessed = {preprocess(txt): txt for txt in installers.keys()}\n",
    "installers_preprocessed\n",
    "\n",
    "# preprocess target\n",
    "df_installer_names['installer_name_preprocessed'] = df_installer_names['installer_name'].apply(lambda x: preprocess(x))\n",
    "\n",
    "# try fuzzy matching\n",
    "from thefuzz import process, fuzz\n",
    "df_installer_names['fuzzy_match'] = df_installer_names['installer_name_preprocessed'].apply(\n",
    "    lambda x: process.extractOne(x, installers_preprocessed.keys(), scorer=fuzz.token_set_ratio))\n",
    "\n",
    "df_installer_names[['fuzzy_match', 'fuzzy_match_score']] = df_installer_names['fuzzy_match'].to_list()\n",
    "df_installer_names\n",
    "\n",
    "df_installer_names['fuzzy_match_score'].value_counts()\n",
    "\n",
    "# merge with counts to\n",
    "df_installer_names = df_installer_names.merge(df_installer_names_counts, on='installer_name')\n",
    "df_installer_names.sort_values(['counts', 'fuzzy_match_score'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 2: Taking those with 100 fuzzy match score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b196fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_match_map = df_installer_names[df_installer_names['fuzzy_match_score'] == 100].copy()\n",
    "fuzzy_match_map['standard_name'] = fuzzy_match_map['fuzzy_match'].map(installers_preprocessed)\n",
    "fuzzy_match_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1098ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging two dataframe with updated installer names\n",
    "col = \"Installer Name\"\n",
    "df = df.merge(fuzzy_match_map[['installer_name', 'standard_name']], \n",
    "              left_on=col, right_on='installer_name',\n",
    "             how='left').drop(columns=['installer_name'])\n",
    "df = df.rename(columns={'standard_name': f\"{col}_standard_name\"})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260af109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(max_cols=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2077a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking how many unique names are in the dataframe \n",
    "unique_installers_count = df['Installer Name_standard_name'].nunique()\n",
    "print(\"Number of unique installers:\", unique_installers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "installer_names = df['Installer Name_standard_name'].unique()\n",
    "\n",
    "# Display the names of all installers\n",
    "print(\"Names of all installers:\")\n",
    "for installer_name in installer_names:\n",
    "    print(installer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Vivint to Sunrun, Lennar solar to Sunnova, Solarcity to Tesla due to acquisitions\n",
    "\n",
    "df['Installer Name_standard_name'] = df['Installer Name_standard_name'].replace({'Vivint': 'Sunrun', 'Lennar': 'Sunnova', 'SolarCity': 'Tesla'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd37771f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking if cleaning worked properly \n",
    "top_installers_names = df['Installer Name_standard_name'].value_counts().head(50)\n",
    "top_installers_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17371659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace rows where 'Installer Name' is not available with \"Other\"\n",
    "# Create a copy of the dataframe\n",
    "df3 = df.copy()\n",
    "\n",
    "# Replace NaN values in 'Installer Name_standard_name' with 'Other'\n",
    "df3['Installer Name_standard_name'].fillna('Other', inplace=True)\n",
    "\n",
    "# Display the updated dataframe\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267248a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move \"Installer Name_standard_name\" column next to \"Installer Name\"\n",
    "columns = df3.columns.tolist()\n",
    "columns.remove(\"Installer Name_standard_name\")\n",
    "columns.insert(columns.index(\"Installer Name\") + 1, \"Installer Name_standard_name\")\n",
    "df4 = df3[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a61ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop not used columns\n",
    "df4 = df4.drop(columns=['CSLB Number', 'Third Party Owned Type', 'Third Party Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace non-\"Rooftop\" values in \"Mounting Method\" column with \"Other\"\n",
    "df4.loc[df4['Mounting Method'] != 'Rooftop', 'Mounting Method'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69822c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all Generator Model columns 1 through 12\n",
    "# Define the columns to be removed\n",
    "columns_to_remove = [f'Generator Model {i}' for i in range(1, 13)]\n",
    "\n",
    "# Drop the columns\n",
    "df4 = df4.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5278f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same process for Inverter models columns 1 through 23\n",
    "\n",
    "# Define the columns to be removed\n",
    "columns_to_remove = [f'Inverter Model {i}' for i in range(1, 23)]\n",
    "\n",
    "# Drop the columns\n",
    "df4 = df4.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c96de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Total System Cost' to numeric, handle errors='coerce' to replace non-numeric values with NaN\n",
    "df4['Total System Cost'] = pd.to_numeric(df4['Total System Cost'], errors='coerce')\n",
    "\n",
    "# Calculate values based on 'Itc Cost Basis' / 0.3 where 'Total System Cost' is blank\n",
    "#df4.loc[df4['Total System Cost'].isna(), 'Total System Cost'] = df4['Itc Cost Basis']/0.3\n",
    "df4.loc[df4['Total System Cost'].isna(), 'Total System Cost'] = df4['Itc Cost Basis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17353f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all Generator manufacturer columns 2 through 12\n",
    "# Define the columns to be removed\n",
    "columns_to_remove = [f'Generator Manufacturer {i}' for i in range(2, 13)]\n",
    "\n",
    "# Drop the columns\n",
    "df4 = df4.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ef9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the specific column\n",
    "df4.rename(columns={'Generator Manufacturer 1': 'Generator_Manufacturer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e691270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same process for Inverter Manufacturer columns 1 through 23\n",
    "# Define the columns to be removed\n",
    "columns_to_remove = [f'Inverter Manufacturer {i}' for i in range(2, 23)]\n",
    "\n",
    "# Drop the columns\n",
    "df4 = df4.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a48b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the specific column\n",
    "df4.rename(columns={'Inverter Manufacturer 1': 'Inverter_Manufacturer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae57c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df4.columns.tolist()\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c908b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new column and fill it with the sum of values in \"Generator Quantity 1\" through \"Generator Quantity 12\"\n",
    "df4['Generator_Quantity'] = df4.loc[:, 'Generator Quantity 1':'Generator Quantity 12'].sum(axis=1)\n",
    "\n",
    "# Drop the columns \"Generator Quantity 1\" through \"Generator Quantity 12\"\n",
    "df4 = df4.drop(columns=[f'Generator Quantity {i}' for i in range(1, 13)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8da31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new column and fill it with the sum of values in \"Inverter Quantity 1\" through \"Inverter Quantity 22\"\n",
    "df4['Inverter_Quantity'] = df4.loc[:, 'Inverter Quantity 1':'Inverter Quantity 22'].sum(axis=1)\n",
    "\n",
    "# Drop the columns \"Inverter Quantity 1\" through \"Inverter Quantity 22\"\n",
    "df4 = df4.drop(columns=[f'Inverter Quantity {i}' for i in range(1, 23)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace spaces with underscores in column names\n",
    "df4.columns = df4.columns.str.replace(' ', '_')\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df4.columns.tolist()\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the old \"Installer_Name\" column\n",
    "df4 = df4.drop(columns=['Installer_Name'])\n",
    "\n",
    "# Rename new \"Installer_Name_standard_name\" into \"Installer Name\"\n",
    "df4.rename(columns={'Installer_Name_standard_name': 'Installer_Name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1844274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ITC Cost Basis column\n",
    "df4 = df4.drop(columns=['Itc_Cost_Basis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22395e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df4.columns.tolist()\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ae857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty cells in \"Installer Name_standard_name\" column with \"Self-installed\" where \"Self Installer\" is \"yes\"\n",
    "df4.loc[df4['Self_Installer'] == 'Yes', 'Installer_Name'] = 'Self-installed'\n",
    "\n",
    "# Drop \"Self-installed\" column\n",
    "df4 = df4.drop(columns=['Self_Installer'])\n",
    "\n",
    "# Display the updated dataframe\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for the system cost that is likely to be wrongly recorded \n",
    "min_acceptable_cost = 7000\n",
    "filtered_system_cost = df4[df4['Total_System_Cost'] < min_acceptable_cost]\n",
    "\n",
    "count = filtered_system_cost.shape[0]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unreosanable datapoints\n",
    "df4 = df4[df4['Total_System_Cost'] >= min_acceptable_cost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning \"Inverter_Manufacturer\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac95a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_inverters_names = df4['Inverter_Manufacturer'].value_counts().head(50)\n",
    "top_inverters_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a55db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the column\n",
    "df_inverter_manufacturer = df4[['Inverter_Manufacturer']].copy()\n",
    "\n",
    "# Replace NaN values with 'Other'\n",
    "df_inverter_manufacturer['Inverter_Manufacturer'].fillna('Other', inplace=True)\n",
    "\n",
    "df_inverter_manufacturer = df_inverter_manufacturer.rename(columns={'Inverter_Manufacturer': 'inverter_manufacturer'})\n",
    "df_inverter_manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e22540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inverter_manufacturer_counts = df_inverter_manufacturer.groupby('inverter_manufacturer').size().reset_index()\n",
    "df_inverter_manufacturer_counts = df_inverter_manufacturer_counts.rename(columns={0: 'counts'})\n",
    "df_inverter_manufacturer_counts['pct'] = df_inverter_manufacturer_counts['counts']/df_inverter_manufacturer_counts['counts'].sum()\n",
    "df_inverter_manufacturer_counts\n",
    "\n",
    "#df_inverter_manufacturer_counts.to_csv('data_files/df_inverter_manufacturer_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12609735",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverters = {\"SolarEdge\": 1,\n",
    "             \"Enphase\": 1,\n",
    "             \"SMA America\": 1,\n",
    "             \"SunPower\": 1,\n",
    "             \"ABB\": 1,\n",
    "             \"Power-One\": 1,\n",
    "             \"Fronius\": 1,\n",
    "             \"Delta\": 1,\n",
    "             \"Ningbo Ginlong\": 1,\n",
    "             \"Xantrex\": 1,\n",
    "             \"Tesla\": 1,\n",
    "             \"PV Powered\": 1,\n",
    "             \"Advanced Energy\": 1,\n",
    "             \"Altenergy\": 1,\n",
    "             \"Kaco\": 1,\n",
    "             \"Maxeon\": 1,\n",
    "             \"Generac\": 1,\n",
    "             \"Pika\": 1,\n",
    "             \"SolarCity\": 1,\n",
    "             \"LG\": 1,\n",
    "             \"Panasonic\": 1,\n",
    "             \"Sanyo\": 1,\n",
    "             \"APSystems\": 1,\n",
    "             \"Chilicon\": 1,\n",
    "             \"Sungrow\": 1,\n",
    "             \"Solaria\": 1,\n",
    "             \"Candian Solar\": 1,\n",
    "             \"Sharp\": 1,\n",
    "             \"Huawei\": 1,\n",
    "             \"Schneider\": 1,\n",
    "             \"Solectria\": 1,\n",
    "             \"SatCon\": 1,\n",
    "             \"Generac\": 1,\n",
    "             \"SolarBridge\": 1,\n",
    "             \"Chint\": 1}\n",
    "\n",
    "df_inverter_manufacturer = df_inverter_manufacturer.drop_duplicates()\n",
    "df_inverter_manufacturer.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11221b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY_SUFFIXES = ['com', 'in', 'int', 'international', 'inc', 'incorporated',\n",
    "                    'incorporation', 'corp', 'corporation', 'cos', 'co', '& co',\n",
    "                    'intl', 'ltd', 'limited', 'plc', 'llc', 'holdings', 'hldgs',\n",
    "                    'partners', 'cl', 'pl', 'technology', 'technologies', 'energy']\n",
    "import re\n",
    "def preprocess(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # removing punctuations in string\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # remove company suffixes:\n",
    "    text = ' '.join([p for p in text.split() if p not in COMPANY_SUFFIXES])\n",
    "    return text.strip()\n",
    "\n",
    "# preprocess candidate column\n",
    "inverters_preprocessed = {preprocess(txt): txt for txt in inverters.keys()}\n",
    "inverters_preprocessed\n",
    "\n",
    "# preprocess target\n",
    "df_inverter_manufacturer['inverter_name_preprocessed'] = df_inverter_manufacturer['inverter_manufacturer'].apply(lambda x: preprocess(x))\n",
    "\n",
    "# try fuzzy matching\n",
    "from thefuzz import process, fuzz\n",
    "df_inverter_manufacturer['fuzzy_match'] = df_inverter_manufacturer['inverter_name_preprocessed'].apply(\n",
    "    lambda x: process.extractOne(x, inverters_preprocessed.keys(), scorer=fuzz.token_set_ratio))\n",
    "\n",
    "df_inverter_manufacturer[['fuzzy_match', 'fuzzy_match_score']] = df_inverter_manufacturer['fuzzy_match'].to_list()\n",
    "df_inverter_manufacturer\n",
    "\n",
    "df_inverter_manufacturer['fuzzy_match_score'].value_counts()\n",
    "\n",
    "# merge with counts to\n",
    "df_inverter_manufacturer = df_inverter_manufacturer.merge(df_inverter_manufacturer_counts, on='inverter_manufacturer')\n",
    "df_inverter_manufacturer.sort_values(['counts', 'fuzzy_match_score'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a1cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inverter_manufacturer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71fed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_match_map = df_inverter_manufacturer[df_inverter_manufacturer['fuzzy_match_score'] == 100].copy()\n",
    "fuzzy_match_map['standard_name'] = fuzzy_match_map['fuzzy_match'].map(inverters_preprocessed)\n",
    "fuzzy_match_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4724301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging two dataframe with updated installer names\n",
    "col = \"Inverter_Manufacturer\"\n",
    "df5 = df4.merge(fuzzy_match_map[['inverter_manufacturer', 'standard_name']], \n",
    "              left_on=col, right_on='inverter_manufacturer',\n",
    "             how='left').drop(columns=['inverter_manufacturer'])\n",
    "df5 = df5.rename(columns={'standard_name': f\"{col}_standard_name\"})\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d18349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Vivint to Sunrun and  Lennar solar to Sunnova due to acquisitions, Solarcity to Tesla\n",
    "\n",
    "df5['Inverter_Manufacturer_standard_name'] = df5['Inverter_Manufacturer_standard_name'].replace({'Vivint': 'Sunrun', 'Lennar': 'Sunnova', 'SolarCity': 'Tesla'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e748651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db95362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values in 'Inverters_Manufacturer_standard_name' with 'Other'\n",
    "df5['Inverter_Manufacturer_standard_name'].fillna('Other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011da1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move \"Inverter_Manufacturer_standard_name\" column next to \"Inverter_Manufacturer\"\n",
    "columns = df5.columns.tolist()\n",
    "columns.remove(\"Inverter_Manufacturer_standard_name\")\n",
    "columns.insert(columns.index(\"Inverter_Manufacturer\") + 1, \"Inverter_Manufacturer_standard_name\")\n",
    "df5 = df5[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66127eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop old column\n",
    "df5 = df5.drop(columns=[\"Inverter_Manufacturer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"Generator_Manufacturer_standard_name\" into 'Generator_Manufacturer'\n",
    "df5 = df5.rename(columns={'Inverter_Manufacturer_standard_name': 'Inverter_Manufacturer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning \"Generator_Manufacturer\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_generator_names = df5['Generator_Manufacturer'].value_counts().head(50)\n",
    "top_generator_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1841682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the column\n",
    "df_generator_manufacturer = df4[['Generator_Manufacturer']].copy()\n",
    "\n",
    "# Replace NaN values with 'Other'\n",
    "df_generator_manufacturer['Generator_Manufacturer'].fillna('Other', inplace=True)\n",
    "\n",
    "df_generator_manufacturer = df_generator_manufacturer.rename(columns={'Generator_Manufacturer': 'generator_manufacturer'})\n",
    "df_generator_manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88808bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generator_manufacturer_counts = df_generator_manufacturer.groupby('generator_manufacturer').size().reset_index()\n",
    "df_generator_manufacturer_counts = df_generator_manufacturer_counts.rename(columns={0: 'counts'})\n",
    "df_generator_manufacturer_counts['pct'] = df_generator_manufacturer_counts['counts']/df_generator_manufacturer_counts['counts'].sum()\n",
    "df_generator_manufacturer_counts\n",
    "\n",
    "#df_generator_manufacturer_counts.to_csv('data_files/df_generator_manufacturer_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a2cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generators = {\"SolarEdge\": 1,\n",
    "              \"Generic Manufacturer\": 1,\n",
    "              \"REC Solar\": 1,\n",
    "              \"Hanwha\": 1,\n",
    "              \"Trina\": 1,\n",
    "              \"Kyocera\": 1,\n",
    "              \"Jinko\": 1,\n",
    "              \"Longi Green Energy\": 1,\n",
    "              \"Yingli Energy\": 1,\n",
    "              \"Hyundai\": 1,\n",
    "              \"Sanyo\": 1,\n",
    "              \"Mission\": 1,\n",
    "              \"Silfab\": 1,\n",
    "              \"Solar World\": 1,\n",
    "              \"BP\": 1,\n",
    "              \"Suniva\": 1,\n",
    "              \"AU Optronics\": 1,\n",
    "              \"SunEdison\": 1,\n",
    "              \"Suntech Power\": 1,\n",
    "              \"Changzhou\": 1,\n",
    "              \"Boviet\": 1,\n",
    "              \"ET\": 1,\n",
    "              \"Evergreen\": 1,\n",
    "              \"Mitsubishi\": 1,\n",
    "              \"Renesola\": 1,\n",
    "              \"Axitec\": 1,\n",
    "              \"Phono\": 1,\n",
    "              \"Sunspark\": 1,\n",
    "              \"Aptos\": 1,\n",
    "              \"CertainTeed\": 1,\n",
    "              \"S-Energy\": 1,\n",
    "              \"Enphase\": 1,\n",
    "              \"JA\": 1,\n",
    "              \"CSI\": 1,\n",
    "              \"SolarWorld\": 1,\n",
    "              \"SMA America\": 1,\n",
    "              \"Schuco\": 1,\n",
    "              \"SunPower\": 1,\n",
    "              \"ABB\": 1,\n",
    "              \"Power-One\": 1,\n",
    "              \"Fronius\": 1,\n",
    "              \"Delta\": 1,\n",
    "              \"Ningbo Ginlong\": 1,\n",
    "              \"Xantrex\": 1,\n",
    "              \"Tesla\": 1,\n",
    "              \"PV Powered\": 1,\n",
    "              \"Advanced Energy\": 1,\n",
    "              \"Altenergy\": 1,\n",
    "              \"Kaco\": 1,\n",
    "              \"Maxeon\": 1,\n",
    "              \"Generac\": 1,\n",
    "              \"Pika\": 1,\n",
    "              \"SolarCity\": 1,\n",
    "              \"LG\": 1,\n",
    "              \"Panasonic\": 1,\n",
    "              \"Sanyo\": 1,\n",
    "              \"APSystems\": 1,\n",
    "              \"Chilicon\": 1,\n",
    "              \"Sungrow\": 1,\n",
    "              \"Solaria\": 1,\n",
    "              \"Candian Solar\": 1,\n",
    "              \"Sharp\": 1,\n",
    "              \"Huawei\": 1,\n",
    "              \"Schneider\": 1,\n",
    "              \"Solectria\": 1,\n",
    "              \"SatCon\": 1,\n",
    "              \"Generac\": 1,\n",
    "              \"SolarBridge\": 1,\n",
    "              \"Chint\": 1,\n",
    "              \"PowerLight\": 1}\n",
    "\n",
    "df_generator_manufacturer = df_generator_manufacturer.drop_duplicates()\n",
    "df_generator_manufacturer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANY_SUFFIXES = ['com', 'in', 'int', 'international', 'inc', 'incorporated',\n",
    "                    'incorporation', 'corp', 'corporation', 'cos', 'co', '& co',\n",
    "                    'intl', 'ltd', 'limited', 'plc', 'llc', 'holdings', 'hldgs',\n",
    "                    'partners', 'cl', 'pl', 'technology', 'technologies', 'energy']\n",
    "import re\n",
    "def preprocess(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # removing punctuations in string\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # remove company suffixes:\n",
    "    text = ' '.join([p for p in text.split() if p not in COMPANY_SUFFIXES])\n",
    "    return text.strip()\n",
    "\n",
    "# preprocess candidate column\n",
    "generators_preprocessed = {preprocess(txt): txt for txt in generators.keys()}\n",
    "generators_preprocessed\n",
    "\n",
    "# preprocess target\n",
    "df_generator_manufacturer['generator_name_preprocessed'] = df_generator_manufacturer['generator_manufacturer'].apply(lambda x: preprocess(x))\n",
    "\n",
    "# try fuzzy matching\n",
    "from thefuzz import process, fuzz\n",
    "df_generator_manufacturer['fuzzy_match'] = df_generator_manufacturer['generator_name_preprocessed'].apply(\n",
    "    lambda x: process.extractOne(x, generators_preprocessed.keys(), scorer=fuzz.token_set_ratio))\n",
    "\n",
    "df_generator_manufacturer[['fuzzy_match', 'fuzzy_match_score']] = df_generator_manufacturer['fuzzy_match'].to_list()\n",
    "df_generator_manufacturer\n",
    "\n",
    "df_generator_manufacturer['fuzzy_match_score'].value_counts()\n",
    "\n",
    "# merge with counts to\n",
    "df_generator_manufacturer = df_generator_manufacturer.merge(df_generator_manufacturer_counts, on='generator_manufacturer')\n",
    "df_generator_manufacturer.sort_values(['counts', 'fuzzy_match_score'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8fcd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generator_manufacturer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fccbd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_match_map = df_generator_manufacturer[df_generator_manufacturer['fuzzy_match_score'] == 100].copy()\n",
    "fuzzy_match_map['standard_name'] = fuzzy_match_map['fuzzy_match'].map(generators_preprocessed)\n",
    "fuzzy_match_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e6dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging two dataframe with updated generators names\n",
    "col = \"Generator_Manufacturer\"\n",
    "df6 = df5.merge(fuzzy_match_map[['generator_manufacturer', 'standard_name']], \n",
    "              left_on=col, right_on='generator_manufacturer',\n",
    "             how='left').drop(columns=['generator_manufacturer'])\n",
    "df7 = df6.rename(columns={'standard_name': f\"{col}_standard_name\"})\n",
    "\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22600ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed990ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_generator_names = df7['Generator_Manufacturer_standard_name'].value_counts().head(50)\n",
    "top_generator_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Vivint to Sunrun and  Lennar solar to Sunnova due to acquisitions, Solarcity to Tesla\n",
    "\n",
    "df7['Generator_Manufacturer_standard_name'] = df7['Generator_Manufacturer_standard_name'].replace({'Vivint': 'Sunrun', 'Lennar': 'Sunnova', 'SolarCity': 'Tesla'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values in 'Generator_Manufacturer_standard_name' with 'Other'\n",
    "df7['Generator_Manufacturer_standard_name'].fillna('Other', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move \"Generator_Manufacturer_standard_name\" column next to \"Generator_Manufacturer\"\n",
    "columns = df7.columns.tolist()\n",
    "columns.remove(\"Generator_Manufacturer_standard_name\")\n",
    "columns.insert(columns.index(\"Generator_Manufacturer\") + 1, \"Generator_Manufacturer_standard_name\")\n",
    "df8 = df7[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088078f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop old column\n",
    "df8 = df8.drop(columns=['Generator_Manufacturer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"Generator_Manufacturer_standard_name\" into 'Generator_Manufacturer'\n",
    "df8 = df8.rename(columns={'Generator_Manufacturer_standard_name': 'Generator_Manufacturer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a334f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider deleting all negative values for storage and inverter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb014f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filing out missing cities in the 'Service_City' column\n",
    "\n",
    "# Group by 'Service_County' and find the most popular 'Service_City'\n",
    "most_popular_city_by_county = df8.groupby('Service_County')['Service_City'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else None).reset_index()\n",
    "\n",
    "# Merge the most popular city data back to the original dataframe\n",
    "df8 = pd.merge(df8, most_popular_city_by_county, on='Service_County', how='left', suffixes=('', '_fill'))\n",
    "\n",
    "# Fill missing values in 'Service_City' with the corresponding most popular city\n",
    "df8['Service_City'] = df8['Service_City'].fillna(df8['Service_City_fill'])\n",
    "\n",
    "# Drop the auxiliary column used for filling\n",
    "df9 = df8.drop(columns=['Service_City_fill'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling out missing zipcode\n",
    "\n",
    "# Group by 'Service_City' and find the most popular 'Service_Zip'\n",
    "most_popular_zip_by_city = df9.groupby('Service_City')['Service_Zip'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else None).reset_index()\n",
    "\n",
    "# Merge the most popular zip data back to the original dataframe\n",
    "df9 = pd.merge(df9, most_popular_zip_by_city, on='Service_City', how='left', suffixes=('', '_fill'))\n",
    "\n",
    "# Fill missing values in 'Service_Zip' with the corresponding most popular zip code\n",
    "df9['Service_Zip'] = df9['Service_Zip'].fillna(df9['Service_Zip_fill'])\n",
    "\n",
    "# Drop the auxiliary column used for filling\n",
    "df10 = df9.drop(columns=['Service_Zip_fill'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in the DataFrame\n",
    "df10.rename(columns={'Storage_Size_(kW_AC)': 'Storage_Size_kW_AC', 'Inverter_Size_(kW_AC)': 'Inverter_Size_kW_AC'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e4c74",
   "metadata": {},
   "source": [
    "## Do some imputating for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccca376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the zip to string\n",
    "df10['Service_Zip'] = df10['Service_Zip'].astype(int).astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91998bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets impute the storage, inverter size, and third party own\n",
    "df10['Storage_Size_kW_AC'] = df10['Storage_Size_kW_AC'].fillna(0)\n",
    "\n",
    "mean_size = df10.Inverter_Size_kW_AC.mean()\n",
    "df10['Inverter_Size_kW_AC'] = df10['Inverter_Size_kW_AC'].fillna(mean_size)\n",
    "\n",
    "df10['Third_Party_Owned'] = df10['Third_Party_Owned'].fillna('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4729dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a year column\n",
    "df10['Year'] = df10['App_Received_Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d628a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace negative values\n",
    "df10['Inverter_Size_kW_AC'] = df10['Inverter_Size_kW_AC'].apply(lambda x: 0 if x < 0 else x)\n",
    "df10['Storage_Size_kW_AC'] = df10['Storage_Size_kW_AC'].apply(lambda x: 0 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccace24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make sure company as at least 100 records other flacg as other and drop\n",
    "installer_count = df10['Installer_Name'].value_counts().to_dict()\n",
    "df_final = df10.copy()\n",
    "\n",
    "def check_count(installer):\n",
    "    if installer_count[installer] >= 10:\n",
    "        return installer\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df_final['Installer_Name'] = df_final['Installer_Name'].apply(check_count)\n",
    "\n",
    "# do some filtering in order to try and improve ML model performance\n",
    "df_final = df_final[df_final['Installer_Name'] != 'Other']\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fc097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate out by utility and export to seperate csv files\n",
    "PGE = df_final[df_final['Utility'] == 'PGE']\n",
    "SCE = df_final[df_final['Utility'] == 'SCE']\n",
    "SDGE = df_final[df_final['Utility'] == 'SDGE']\n",
    "\n",
    "PGE.to_csv(data_dir + 'df_PGE.csv', index=False)\n",
    "SCE.to_csv(data_dir + 'df_SCE.csv', index=False)\n",
    "SDGE.to_csv(data_dir + 'df_SDGE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the entire file out\n",
    "df_final.to_csv(data_dir + 'df_ALL-ML.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc437534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
